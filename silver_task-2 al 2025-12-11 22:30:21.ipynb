{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8166d3b8-f806-4c5a-bdf8-7f27a49a9afe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from delta.tables import DeltaTable\n",
    "from pyspark.sql.window import Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "13d294de-46dd-4de4-a8e8-f360a6663ab5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "tables = ['customers','products','categories','orders','payments',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0aa7cd01-892d-4644-8700-dde7d907067a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "for table in tables:\n",
    "    df = spark.sql(f'select * from main.bronze_al.{table}')\n",
    "\n",
    "    numeric_col=[c for c in df.columns if 'amount' in c.lower() or 'price' in c.lower()]\n",
    "    for i in numeric_col:\n",
    "        df = df.withColumn(i, col(i).cast('double'))\n",
    "\n",
    "    primary_keys = {\n",
    "    \"customers\": \"customer_id\",\n",
    "    \"products\": \"product_id\",\n",
    "    \"categories\": \"category_id\",\n",
    "    \"orders\": \"order_id\",\n",
    "    \"payments\": \"payment_id\"\n",
    "    }\n",
    "    pk = primary_keys[table]\n",
    "\n",
    "    df = df.filter(col(pk).isNotNull())\n",
    "    \n",
    "    silver_table = f'main.silver_al.{table}'\n",
    "    \n",
    "    windows  = Window.partitionBy(pk).orderBy(col('ingest_time').desc(),col('source_file').desc())\n",
    "    df= df.withColumn('rn', row_number().over(windows)).filter(col('rn')==1).drop('rn')\n",
    "\n",
    "\n",
    "    if table in ['orders','payments']:\n",
    "        if spark.catalog.tableExists(silver_table):\n",
    "            delta = DeltaTable.forName(spark,silver_table)\n",
    "            delta.alias('trg').merge(df.alias('src'),f'src.{pk}=trg.{pk}')\\\n",
    "            .whenMatchedUpdateAll()\\\n",
    "            .whenNotMatchedInsertAll().execute()\n",
    "        else:\n",
    "            df.write.format('delta').mode('overwrite').saveAsTable(silver_table)\n",
    "    else:\n",
    "         df.write.format('delta').mode('overwrite').option('overwriteSchema',True).saveAsTable(silver_table)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "silver_task-2 al 2025-12-11 22:30:21",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
